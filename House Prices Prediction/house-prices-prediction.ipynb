{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Background Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an analyst estimates the price of a house, they need to consider many predictors, including its location, size, and construction quality. Luckily, machine learning models exist to do the work for them. In this project, I trained and evaluated regression models to predict house prices. I used a dataset from OpenIntro of 2930 houses in Ames, Iowa with 79 predictors. To download the dataset and read the predictor descriptions, [click here](https://www.openintro.org/data/index.php?data=ames). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Order column (unique identifier for each house) as the row index\n",
    "houses_data = pd.read_csv(\"ames_houses_data.csv\", index_col=\"Order\")\n",
    "X = houses_data.drop(columns=[\"price\"])\n",
    "y = houses_data.loc[:, \"price\"]\n",
    "print(\"X size: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, I only used countinuous, discrete, and ordinal predictors to train my models. Hence, I removed all of the nominal predictors from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.select_dtypes(include=\"number\")\n",
    "\n",
    "# Manually remove nominal columns encoded with integers\n",
    "X.drop(columns=[\"MS.SubClass\", \"Mo.Sold\", \"PID\"], inplace=True)\n",
    "\n",
    "print(\"X size after removing unwanted predictors: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then split the dataset into a training set (80%) and a test set (20%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train size: \", X_train.shape)\n",
    "print(\"X_test size: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of house prices (the target)\n",
    "sns.histplot(y_train)\n",
    "plt.title(\"The distribution of house prices is positively skewed\")\n",
    "plt.xlabel(\"House price ($US)\")\n",
    "plt.ylabel(\"No. of houses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of house prices is positively skewed due to a few very expensive houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if you want to run (takes a while).\n",
    "# X_train.hist(figsize=(15, 17))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](predictor_histograms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the predictors (Pool.Area, Screen.Porch) are 0 for most of the houses. For example:\n",
    "- **Pool.Area**: Pool area \n",
    "- **Screen.Porch**: Screen porch area\n",
    "\n",
    "This is because most houses do not have these amenities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large number of predictors, a correlation heatmap would be hard to read. Hence, I did not include one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()\n",
    "lower_triangle_mask = np.tril(np.ones(correlation_matrix.shape), k=-1).astype(bool)\n",
    "# Replace all values above the lower triangle with NaN\n",
    "correlation_matrix = correlation_matrix.where(lower_triangle_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with the target (house price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive = correlation_matrix.loc[\"price\"].sort_values(ascending=False)[0:5]\n",
    "print(\n",
    "    f\"The {len(most_positive)} predictors that were most positively correlated with house price were:\\n\",\n",
    "    most_positive,\n",
    "    \"\\n\",\n",
    "    sep=\"\",\n",
    ")\n",
    "\n",
    "most_negative = correlation_matrix.loc[\"price\"].sort_values(ascending=True)[0:1]\n",
    "print(\n",
    "    f\"The predictor that was most negatively correlated with house price was:\\n\",\n",
    "    most_negative,\n",
    "    sep=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Overall.Qual**: Quality of the construction materials and workmanship on a scale of 1 to 10. \n",
    "- **area**: The total living area above the ground. \n",
    "- **Garage.Cars**: No. of cars that can fit in the garage. \n",
    "- **Total.Bsmt.SF**: The area of the basement.\n",
    "- **Garage.Area**: Area of the garage. (Notice that is is highly correlated with GarageCars). \n",
    "\n",
    "None of the predictors were significantly negatively correlated with the house price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive = correlation_matrix.stack().sort_values(ascending=False)[0:5]\n",
    "print(\n",
    "    f\"The {len(most_positive)} predictor pairs that were most positively correlated were:\\n\",\n",
    "    most_positive,\n",
    "    \"\\n\",\n",
    "    sep=\"\",\n",
    ")\n",
    "\n",
    "most_negative = correlation_matrix.stack().sort_values(ascending=True)[0:1]\n",
    "print(\n",
    "    f\"The predictor pair that was most negatively correlated was:\\n\",\n",
    "    most_negative,\n",
    "    sep=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collinear predictors (multicollinearity) increase the uncertainty in the estimated regression coefficients, which makes models less interpretable. However, they do not affect prediction accuracy, so I will not remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Set Procesesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each step in the data processing can be represented by a scikit-learn transformer object. These transfromers can be assembled into a Pipeline object, which can be used to apply all of the data processing steps to new data in one method call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use scikit-learn's StandardScaler transformer to standardize each predictor variable to a mean of 0 and a standard deviation of 1. This will improve the training speed and performance of the regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression models cannot be trained on data with missing values. The simplest solution is to delete data points with missing values. But data points with a few missing predictor values still have a lot of information in their other predictor values. So a better option is to replace missing data with a best guess based on other data in the dataset (data imputation). \n",
    "\n",
    "I will use the KNNImputer transformer to impute missing data. For each data point with missing predictor values, k-Nearest Neighbors:\n",
    "1. Identifies the k data points that are closest to it in the predictor space.\n",
    "2. Takes the averages of their predictor values and uses them to impute the missing values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_processing = make_pipeline(StandardScaler(), KNNImputer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing High Leverage Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High leverage points (HLPs) are far away from other data points in the predictor space. They can worsen the fit on the rest of the data points. I will use the IsolationForest estimator to identify HLPs, then I will manually remove them. I will use principal component analysis to visually estimate the threshold for HLP classification. Technically, this should be a step in the data processing pipeline, but scikit-learn does not support HLP removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_HLP(\n",
    "    pred_HLP: np.ndarray, X: pd.DataFrame, y: pd.Series\n",
    ") -> (pd.DataFrame, pd.Series):\n",
    "    num_HLP = np.count_nonzero((pred_HLP == -1))\n",
    "    perc_HLP = num_HLP / len(y_train) * 100\n",
    "    print(f\"{perc_HLP: .2f}% of the data points were identified as HLPs and removed.\")\n",
    "\n",
    "    not_HLP = pred_HLP == 1\n",
    "    return (X[not_HLP], y[not_HLP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_old = X_train  # keep a copy to plot the removed HLPs\n",
    "hlp_pipe = make_pipeline(\n",
    "    data_processing, IsolationForest(random_state=42, contamination=0.004)\n",
    ")\n",
    "hlp_pipe.fit(X_train)\n",
    "X_train, y_train = remove_HLP(hlp_pipe.predict(X_train), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use principal component analysis (PCA) to estimate an appropriate HLP classification threshold. PCA summarizes the variance in the predictor space in a lower-dimensional principal component space. Hence, high leverage points are also isolated in the principal component space, where they can be visually identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipe = make_pipeline(data_processing, PCA(n_components=2))\n",
    "pc_scores = pd.DataFrame(pca_pipe.fit_transform(X_train_old), columns=[\"PC1\", \"PC2\"])\n",
    "is_HLP = pd.Series((hlp_pipe.predict(X_train_old) == -1), name=\"is_HLP\")\n",
    "pc_scores = pd.concat([pc_scores, is_HLP], axis=1)\n",
    "\n",
    "ax = sns.scatterplot(data=pc_scores, x=\"PC1\", y=\"PC2\", hue=\"is_HLP\")\n",
    "plt.title(\"There are high leverage points in the training data\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, [\"Normal House\", \"HLP House\"], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest models we can use to predict the house prices is multiple linear regression. I will now train a multiple linear regression model on the entire training set then fit it on the training set to obtain a residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipe = make_pipeline(data_processing, LinearRegression())\n",
    "linear_pipe.fit(X_train, y_train)\n",
    "pred_y_train = pd.Series(linear_pipe.predict(X_train), index=X_train.index)\n",
    "train_residuals = y_train - pred_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    x=pred_y_train, y=train_residuals, scatter_kws={\"alpha\": 0.2}, lowess=True\n",
    ")  # locally weighted linear regression\n",
    "\n",
    "plt.title(\"Multiple linear regression underfits the training data\")\n",
    "plt.xlabel(\"Predicted house price\")\n",
    "plt.ylabel(\"Residual ($US)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual plot is curved, which suggests that linear regression underfits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test set is reserved for the evaluation of our final model, I will use cross-validation to evaluate the multiple linear regression model. Since I will be evaluating many regression models, I will create a function to calculate the regression scores for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def regression_scores(reg_pipe: Pipeline) -> dict:\n",
    "    reg_scores = cross_validate(\n",
    "        reg_pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "    )\n",
    "    train_scores = reg_scores[\"train_score\"]\n",
    "    print(\n",
    "        f\"Mean NRMSE for training sets: {train_scores.mean():.2f} ({train_scores.std():.2f} SD)\"\n",
    "    )\n",
    "    test_scores = reg_scores[\"test_score\"]\n",
    "    print(\n",
    "        f\"Mean NRMSE for validation sets: {test_scores.mean():.2f} ({test_scores.std():.2f} SD)\"\n",
    "    )\n",
    "    return reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_scores = regression_scores(linear_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the negative root mean square error (NRMSE) scores, the better the model is. The scores for the training sets and validation sets are very similar, suggesting the model may be underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To increase model complexity, I will add second-order predictors that are powers and products of the original predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quad_pipe = make_pipeline(\n",
    "    data_processing, PolynomialFeatures(degree=2), LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_pipe.fit(X_train, y_train)\n",
    "quadratic = quad_pipe[\"linearregression\"]\n",
    "num_coef = len(quadratic.coef_[quadratic.coef_ != 0])\n",
    "print(f\"Number of coefficients: {num_coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are a lot of predictors compared to the number of data points (around 2000), so we expect the model to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_scores = regression_scores(quad_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the score is much higher for the training sets than the validation sets, the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lasso regression restricts the magnitudes of the regression coefficients to prevent overfitting. It can also set coefficients to 0, effectively removing predictors from the model. The amount of restriction is controlled by a hyperparameter ($\\alpha$). \n",
    "\n",
    "Hyperparameter values are empirically determined by trying a range of different values and seeing which one yields the lowest prediction errors. This process is called hyperparameter tuning and can be accomplished using GridSearchCV(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I started with a very wide search range between 0.1 and 100,000, then narrowed it down.\n",
    "param_grid = {\"alpha\": np.linspace(500, 1500, num=5)}\n",
    "search_pipe = make_pipeline(\n",
    "    data_processing,\n",
    "    PolynomialFeatures(degree=2),\n",
    "    GridSearchCV(Lasso(), param_grid, cv=2, scoring=\"neg_root_mean_squared_error\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_scores = regression_scores(search_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean score on the validation set is the highest out of all the models tested so far, indicating that this is the best model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below returns the obtained $\\alpha$ value for each cross-validation iteration to help me tune the range of $\\alpha$ values to test in GridSearchCV()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cv_hyperparams(reg_scores: dict):\n",
    "    # retrieve a list of the tuned pipelines\n",
    "    search_pipes = reg_scores[\"estimator\"]\n",
    "    print(\"The best hyperparameter values for each CV iteration were:\")\n",
    "    for i, search_pipe in enumerate(search_pipes):\n",
    "        search = search_pipe[\"gridsearchcv\"]\n",
    "        print(search.best_params_)\n",
    "\n",
    "\n",
    "print_cv_hyperparams(reg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of variance in the tuned models' hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the quadratic lasso model performs well, I will now train it on the entire training set then evaluate it using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha\": np.linspace(600, 1100, num=5)}\n",
    "search_pipe = make_pipeline(\n",
    "    data_processing,\n",
    "    PolynomialFeatures(degree=2),\n",
    "    GridSearchCV(Lasso(), param_grid, cv=3, scoring=\"neg_root_mean_squared_error\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pipe.fit(X_train, y_train)\n",
    "search = search_pipe[\"gridsearchcv\"]\n",
    "best_alpha = search.best_params_[\"alpha\"]\n",
    "mean_test_scores = search.cv_results_[\"mean_test_score\"]\n",
    "alpha_vs_NRMSE = pd.DataFrame(mean_test_scores, param_grid[\"alpha\"])\n",
    "\n",
    "sns.lineplot(alpha_vs_NRMSE, legend=False)\n",
    "\n",
    "plt.title(f\"The best alpha value is {int(best_alpha)}\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Validation Set NRMSE Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pipe = make_pipeline(\n",
    "    data_processing, PolynomialFeatures(degree=2), Lasso(alpha=best_alpha)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso_pipe.fit(X_train, y_train)\n",
    "lasso = lasso_pipe[\"lasso\"]\n",
    "num_coef = len(lasso.coef_)\n",
    "num_zero_coef = len(lasso.coef_[lasso.coef_ == 0])\n",
    "print(f\"Number of non-zero coefficients: {(num_coef - num_zero_coef)}\")\n",
    "print(f\"Percentage of coefficients removed: {int(num_zero_coef / num_coef * 100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike quadratic regression, quadratic lasso regression does not overfit the data because it removes many of the predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = remove_HLP(hlp_pipe.predict(X_test), X_test, y_test)\n",
    "pred_y_test = pd.Series(lasso_pipe.predict(X_test), index=X_test.index)\n",
    "\n",
    "print(f\"Test set NRMSE score: {-np.sqrt(mean_squared_error(y_test, pred_y_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set score is similar to the average validation set score. This suggests the model did not overfit the training set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
